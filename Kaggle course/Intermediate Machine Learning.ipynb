{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "310f79f3",
   "metadata": {},
   "source": [
    "# Intermediate Machine Learning [Kaggle] - notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74486ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X_full = pd.read_csv('train.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "X = X_full.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18623bec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>20</td>\n",
       "      <td>90.0</td>\n",
       "      <td>11694</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>452.0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>774</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>20</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6600</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1962</td>\n",
       "      <td>1962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>30</td>\n",
       "      <td>80.0</td>\n",
       "      <td>13360</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1921</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>713</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>432</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13265</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2002</td>\n",
       "      <td>2002</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>857</td>\n",
       "      <td>150</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>20</td>\n",
       "      <td>118.0</td>\n",
       "      <td>13704</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>843</td>\n",
       "      <td>468</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "Id                                                                           \n",
       "619          20         90.0    11694            9            5       2007   \n",
       "871          20         60.0     6600            5            5       1962   \n",
       "93           30         80.0    13360            5            7       1921   \n",
       "818          20          NaN    13265            8            5       2002   \n",
       "303          20        118.0    13704            7            5       2001   \n",
       "\n",
       "     YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageArea  \\\n",
       "Id                                                     ...               \n",
       "619          2007       452.0          48           0  ...         774   \n",
       "871          1962         0.0           0           0  ...         308   \n",
       "93           2006         0.0         713           0  ...         432   \n",
       "818          2002       148.0        1218           0  ...         857   \n",
       "303          2002       150.0           0           0  ...         843   \n",
       "\n",
       "     WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  \\\n",
       "Id                                                                              \n",
       "619           0          108              0          0          260         0   \n",
       "871           0            0              0          0            0         0   \n",
       "93            0            0             44          0            0         0   \n",
       "818         150           59              0          0            0         0   \n",
       "303         468           81              0          0            0         0   \n",
       "\n",
       "     MiscVal  MoSold  YrSold  \n",
       "Id                            \n",
       "619        0       7    2007  \n",
       "871        0       8    2009  \n",
       "93         0       8    2009  \n",
       "818        0       7    2008  \n",
       "303        0       1    2006  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b330b6",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a1ae83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 36)\n",
      "LotFrontage    212\n",
      "MasVnrArea       6\n",
      "GarageYrBlt     58\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Shape of training data (num_rows, num_columns)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "545b0c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80f690",
   "metadata": {},
   "source": [
    "#### Drop Columns with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71a92fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: get names of columns with missing values\n",
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()]\n",
    "\n",
    "# Fill in the lines below: drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_valid = X_valid.drop(cols_with_missing, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "111cd9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Drop columns with missing values):\n",
      "17837.82570776256\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b694d35",
   "metadata": {},
   "source": [
    "#### Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd14238e",
   "metadata": {},
   "source": [
    "Imputation fills in the missing values with some number. For instance, we can fill in the mean value along each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba81f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Fill in the lines below: imputation\n",
    "my_imputer = SimpleImputer()\n",
    "\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
    "\n",
    "# Fill in the lines below: imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42ed1ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Imputation):\n",
      "18062.894611872147\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE (Imputation):\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60311b",
   "metadata": {},
   "source": [
    "#### An Extension To Imputation\n",
    "\n",
    "Imputation is the standard approach, and it usually works well. However, imputed values may be systematically above or below their actual values (which weren't collected in the dataset). Or rows with missing values may be unique in some other way. In that case, your model would make better predictions by considering which values were originally missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "545c683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessed training and validation features\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "final_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "final_X_train = pd.DataFrame(final_imputer.fit_transform(X_train))\n",
    "final_X_valid = pd.DataFrame(final_imputer.transform(X_valid))\n",
    "\n",
    "# Fill in the lines below: imputation removed column names; put them back\n",
    "final_X_train.columns = X_train.columns\n",
    "final_X_valid.columns = X_valid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a36176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Your approach):\n",
      "17791.59899543379\n"
     ]
    }
   ],
   "source": [
    "# Define and fit model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model.fit(final_X_train, y_train)\n",
    "\n",
    "# Get validation predictions and MAE\n",
    "preds_valid = model.predict(final_X_valid)\n",
    "print(\"MAE (Your approach):\")\n",
    "print(mean_absolute_error(y_valid, preds_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe3281",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee985815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X = pd.read_csv('train.csv', index_col='Id') \n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# To keep things simple, we'll drop columns with missing values\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      train_size=0.8, test_size=0.2,\n",
    "                                                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c0b0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0983bf",
   "metadata": {},
   "source": [
    "#### Drop Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "973f8696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the lines below: drop columns in training and validation data\n",
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a957fce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "17837.82570776256\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cbcd731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Condition2' column in training data: ['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']\n",
      "\n",
      "Unique values in 'Condition2' column in validation data: ['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10992a",
   "metadata": {},
   "source": [
    "#### Ordinal Encoding\n",
    "\n",
    "Ordinal encoding assigns each unique value to a different integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6f195f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be ordinal encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Functional', 'Condition2', 'RoofMatl']\n"
     ]
    }
   ],
   "source": [
    "# Categorical columns in the training data\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Columns that can be safely ordinal encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_valid[col]).issubset(set(X_train[col]))]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f5a5959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Apply ordinal encoder \n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "label_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "591955ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Ordinal Encoding):\n",
      "17098.01649543379\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 2 (Ordinal Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48485b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('Utilities', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('ExterQual', 4),\n",
       " ('KitchenQual', 4),\n",
       " ('MSZoning', 5),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('HeatingQC', 5),\n",
       " ('Condition2', 6),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('Heating', 6),\n",
       " ('Functional', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('SaleType', 9),\n",
       " ('Exterior1st', 15),\n",
       " ('Exterior2nd', 16),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f69a82",
   "metadata": {},
   "source": [
    "Investigating cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98f4e710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be one-hot encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Exterior2nd', 'Exterior1st', 'Neighborhood']\n"
     ]
    }
   ],
   "source": [
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38543317",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding\n",
    "\n",
    "One-hot encoding creates new columns indicating the presence (or absence) of each possible value in the original data. To understand this, we'll work through an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d148cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Use as many lines of code as you need!\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8bd5481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (One-Hot Encoding):\n",
      "17525.345719178084\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecfde7a",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f15c85a",
   "metadata": {},
   "source": [
    "Pipelines are a simple way to keep your data preprocessing and modeling code organized. Specifically, a pipeline bundles preprocessing and modeling steps so you can use the whole bundle as if it were a single step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd9b7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X_full = pd.read_csv('train.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full.SalePrice\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X_full, y, \n",
    "                                                                train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in X_train_full.columns if\n",
    "                    X_train_full[cname].nunique() < 10 and \n",
    "                    X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X_train_full.columns if \n",
    "                X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cccd96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 17861.780102739725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)\n",
    "                     ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = clf.predict(X_valid)\n",
    "\n",
    "print('MAE:', mean_absolute_error(y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43cc6b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='constant') # Your code here\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bd01a5",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0732f5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "train_data = pd.read_csv('train.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "train_data.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = train_data.SalePrice              \n",
    "train_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Select numeric columns only\n",
    "numeric_cols = [cname for cname in train_data.columns if train_data[cname].dtype in ['int64', 'float64']]\n",
    "X = train_data[numeric_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "989a299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', SimpleImputer()),\n",
    "    ('model', RandomForestRegressor(n_estimators=50, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c86cdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MAE score: 18276.410356164386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"Average MAE score:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a4c20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(n_estimators):\n",
    "    \"\"\"Return the average MAE over 3 CV folds of random forest model.\n",
    "    \n",
    "    Keyword argument:\n",
    "    n_estimators -- the number of trees in the forest\n",
    "    \"\"\"\n",
    "    # Replace this body with your own code\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n",
    "                              ('model', RandomForestRegressor(n_estimators=n_estimators,\n",
    "                                                              random_state=0))\n",
    "                             ])\n",
    "    \n",
    "    scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=3,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "379ec3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "x = 50\n",
    "while x <= 400:\n",
    "    results[x] = get_score(x)\n",
    "    x += 50\n",
    "\n",
    "results = results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45d3804e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(list(results.keys()), list(results.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5456ba",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221d6139",
   "metadata": {},
   "source": [
    "n_estimators specifies how many times to go through the modeling cycle described above. It is equal to the number of models that we include in the ensemble.\n",
    "\n",
    "early_stopping_rounds offers a way to automatically find the ideal value for n_estimators. Early stopping causes the model to stop iterating when the validation score stops improving, even if we aren't at the hard stop for n_estimators. It's smart to set a high value for n_estimators and then use early_stopping_rounds to find the optimal time to stop iterating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22832aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the data\n",
    "X = pd.read_csv('train.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice              \n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numeric_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "\n",
    "# One-hot encode the data (to shorten the code, we use pandas)\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_valid = pd.get_dummies(X_valid)\n",
    "X_train, X_valid = X_train.align(X_valid, join='left', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ca51daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=6, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the model\n",
    "my_model_1 = XGBRegressor(random_state=0) # Your code here\n",
    "\n",
    "# Fit the model\n",
    "my_model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f0faf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Get predictions\n",
    "predictions_1 = my_model_1.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d2bebd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 17662.736729452055\n"
     ]
    }
   ],
   "source": [
    "# Calculate MAE\n",
    "mae_1 = mean_absolute_error(y_valid, predictions_1) # Your code here\n",
    "\n",
    "# Uncomment to print MAE\n",
    "print(\"Mean Absolute Error:\" , mae_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4360a4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 16688.691513270547\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "my_model_2 = XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "\n",
    "# Fit the model\n",
    "my_model_2.fit(X_train,y_train)\n",
    "\n",
    "# Get predictions\n",
    "predictions_2 = my_model_2.predict(X_valid)\n",
    "\n",
    "# Calculate MAE\n",
    "mae_2 = mean_absolute_error(y_valid, predictions_2) # Your code here\n",
    "\n",
    "# Uncomment to print MAE\n",
    "print(\"Mean Absolute Error:\" , mae_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee16b0ab",
   "metadata": {},
   "source": [
    "### Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a609d8",
   "metadata": {},
   "source": [
    "Target leakage occurs when your predictors include data that will not be available at the time you make predictions.\n",
    "\n",
    "Recall that validation is meant to be a measure of how the model does on data that it hasn't considered before. You can corrupt this process in subtle ways if the validation data affects the preprocessing behavior. This is sometimes called train-test contamination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57a70e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
